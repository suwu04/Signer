<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sign Language Translator (Web)</title>
    <!-- 1. Load Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* Custom styles */
        body { font-family: 'Inter', sans-serif; }
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');
        
        /* Custom modal style */
        .modal {
            display: none; /* Hidden by default */
            position: fixed; /* Stay in place */
            z-index: 1000; /* Sit on top */
            left: 0; top: 0;
            width: 100%; height: 100%;
            overflow: auto; /* Enable scroll if needed */
            background-color: rgba(0,0,0,0.4); /* Black w/ opacity */
        }
        .modal-content {
            background-color: #fefefe;
            margin: 15% auto; /* 15% from the top and centered */
            padding: 24px;
            border-radius: 12px;
            width: 90%;
            max-width: 400px;
            box-shadow: 0 10px 25px rgba(0,0,0,0.2);
        }
        /* Style for the mic button when listening */
        .listening {
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7); }
            70% { box-shadow: 0 0 0 10px rgba(239, 68, 68, 0); }
            100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0); }
        }
    </style>
</head>
<body class="bg-gray-100 flex flex-col items-center justify-center min-h-screen p-4">

    <h1 class="text-3xl font-bold text-gray-800 mb-6">Welcome to SignBridge</h1>

    <div class="w-full max-w-6xl mx-auto bg-white rounded-xl shadow-2xl p-6 md:p-8 flex flex-col md:flex-row">

        <!-- Left Panel: Animation Display -->
        <div class="w-full md:w-3/5 relative aspect-video bg-gray-900 rounded-lg overflow-hidden">
            <!-- Canvas: For drawing (future use) or just as a base -->
            <canvas id="display_canvas" class="w-full h-full absolute top-0 left-0"></canvas>
            
            <!-- Placeholder: Shown on load -->
            <div id="placeholder" class="w-full h-full flex items-center justify-center">
                <p class="text-gray-400 text-lg">Enter text to see sign animation.</p>
            </div>

            <!-- Animation Overlay: For Text -> Sign -->
            <div id="animation_overlay" class="w-full h-full absolute top-0 left-0 bg-gray-900 flex-col items-center justify-center hidden p-4">
                <img id="animation_img" src="" alt="Sign" class="max-w-full max-h-[80%] object-contain rounded-lg">
                <div id="animation_label" class="mt-4 p-2 px-4 bg-black bg-opacity-50 text-white text-2xl font-semibold rounded-lg">
                    SIGN: Hello
                </div>
            </div>
        </div>

        <!-- Right Panel: Controls -->
        <div class="w-full md:w-2/5 md:pl-8 mt-6 md:mt-0">
            <div class="flex flex-col h-full">

                <!-- Text -> Sign -->
                <div class="mt-6">
                    <label class="block text-sm font-medium text-gray-700">Text → Sign:</label>
                    <div class="mt-2 flex items-center space-x-2">
                        <input id="text_entry" type="text" placeholder="Enter text or use mic..." class="w-full px-4 py-3 bg-gray-200 text-gray-800 rounded-lg border border-gray-300 focus:outline-none focus:ring-2 focus:ring-blue-500">
                        <!-- New Mic Button -->
                        <button id="mic_btn" title="Speak to Text and Convert" class="flex-shrink-0 w-12 h-12 bg-gray-700 hover:bg-gray-800 text-white rounded-full flex items-center justify-center shadow transition-all">
                            <!-- SVG Mic Icon -->
                            <svg class="w-6 h-6" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M7 4a3 3 0 016 0v4a3 3 0 11-6 0V4zm4 10.93A7.001 7.001 0 0017 8a1 1 0 10-2 0A5 5 0 015 8a1 1 0 10-2 0 7.001 7.001 0 006 6.93V17H6a1 1 0 100 2h8a1 1 0 100-2h-3v-2.07z" clip-rule="evenodd"></path></svg>
                        </button>
                    </div>
                    <!-- REMOVED: Convert Text → Sign button -->
                </div>

                <!-- Output Box -->
                <div class="flex-grow mt-6 bg-gray-900 text-white text-xs font-mono p-4 rounded-lg overflow-y-auto h-48 min-h-[12rem]">
                    <div id="status_output"></div>
                </div>
            </div>
        </div>
    </div>
    
    <!-- Footer for Attribution (Dark Blue Bar) -->
    <footer class="w-full max-w-6xl mx-auto mt-4 p-3 bg-gray-800 text-white rounded-lg shadow-2xl text-center">
        <p class="text-sm">Contributed by Suraj Sajeevan, G. Chandrasekhar, Deeraj A.K</p>
    </footer>

    <!-- Modal for Errors -->
    <div id="error_modal" class="modal">
        <div class="modal-content">
            <h2 id="modal_title" class="text-xl font-bold text-gray-800 mb-4">Modal Title</h2>
            <p id="modal_message" class="text-gray-600 mb-6">This is the modal message.</p>
            <button id="modal_close_btn" class="w-full bg-blue-600 hover:bg-blue-700 text-white font-semibold py-2 px-4 rounded-lg transition-all">
                OK
            </button>
        </div>
    </div>

    <!-- --- MAPS --- (Pre-filled from your screenshots) -->
    <script>
        const WORDS_MAP = {
            "bad": "examples_per_class/00_Bad.jpg", "brother": "examples_per_class/01_Brother.jpg", "father": "examples_per_class/02_Father.jpg",
            "food": "examples_per_class/03_Food.jpg", "friend": "examples_per_class/04_Friend.jpg", "good": "examples_per_class/05_Good.jpg",
            "hello": "examples_per_class/06_Hello.jpg", "help": "examples_per_class/07_Help.jpg", "house": "examples_per_class/08_House.jpg",
            "i": "examples_per_class/09_I.jpg", "indian": "examples_per_class/10_Indian.jpg", "loud": "examples_per_class/11_Loud.jpg",
            "mummy": "examples_per_class/12_Mummy.jpg", "namaste": "examples_per_class/13_Namaste.jpg", "name": "examples_per_class/14_Name.jpg",
            "no": "examples_per_class/15_No.jpg", "place": "examples_per_class/16_Place.jpg", "please": "examples_per_class/17_Please.jpg",
            "quiet": "examples_per_class/18_Quiet.jpg", "sleeping": "examples_per_class/19_Sleeping.jpg", "sorry": "examples_per_class/20_Sorry.jpg",
            "strong": "examples_per_class/21_Strong.jpg", "thank-you": "examples_per_class/22_Thank-you.jpg", "time": "examples_per_class/23_Time.jpg",
            "today": "examples_per_class/24_Today.jpg", "water": "examples_per_class/25_Water.jpg", "what": "examples_per_class/26_What.jpg",
            "yes": "examples_per_class/27_Yes.jpg", "your": "examples_per_class/28_Your.jpg", "language": "examples_per_class/29_language.jpg",
            "sign": "examples_per_class/30_sign.jpg", "you": "examples_per_class/31_you.jpg"
        };

        const LETTERS_MAP = {
            "0": "examples_per_class_l/00_00.jpg", "1": "examples_per_class_l/01_01.jpg", "2": "examples_per_class_l/02_02.jpg", "3": "examples_per_class_l/03_03.jpg",
            "4": "examples_per_class_l/04_04.jpg", "5": "examples_per_class_l/05_05.jpg", "6": "examples_per_class_l/06_06.jpg", "7": "examples_per_class_l/07_07.jpg",
            "8": "examples_per_class_l/08_08.jpg", "9": "examples_per_class_l/09_09.jpg", "a": "examples_per_class_l/10_A.jpg", "b": "examples_per_class_l/11_B.jpg",
            "c": "examples_per_class_l/12_C.jpg", "d": "examples_per_class_l/13_D.jpg", "e": "examples_per_class_l/14_E.jpg", "f": "examples_per_class_l/15_F.jpg",
            "g": "examples_per_class_l/16_G.jpg", "h": "examples_per_class_l/17_H.jpg", "i": "examples_per_class_l/18_I.jpg", "j": "examples_per_class_l/19_J.jpg",
            "k": "examples_per_class_l/20_K.jpg", "l": "examples_per_class_l/21_L.jpg", "m": "examples_per_class_l/22_M.jpg", "n": "examples_per_class_l/23_N.jpg",
            "o": "examples_per_class_l/24_O.jpg", "p": "examples_per_class_l/25_P.jpg", "q": "examples_per_class_l/26_Q.jpg", "r": "examples_per_class_l/27_R.jpg",
            "s": "examples_per_class_l/28_S.jpg", "t": "examples_per_class_l/29_T.jpg", "u": "examples_per_class_l/30_U.jpg", "v": "examples_per_class_l/31_V.jpg",
            "w": "examples_per_class_l/32_W.jpg", "x": "examples_per_class_l/33_X.jpg", "y": "examples_per_class_l/34_Y.jpg", "z": "examples_per_class_l/35_Z.jpg"
        };
    </script>

    <!-- --- JAVASCRIPT LOGIC --- -->
    <script>
        // --- Global State & UI Elements ---
        let canvas, ctx, placeholder, animationOverlay, animationImg, animationLabel, textEntry, statusOutput, micBtn;
        let playingAnimation = false, playFrames = [], playIndex = 0;
        const FRAME_DURATION_MS = 900;
        
        // --- Initialization ---
        document.addEventListener('DOMContentLoaded', () => {
            // Get all UI elements
            canvas = document.getElementById('display_canvas');
            ctx = canvas.getContext('2d');
            placeholder = document.getElementById('placeholder');
            animationOverlay = document.getElementById('animation_overlay');
            animationImg = document.getElementById('animation_img');
            animationLabel = document.getElementById('animation_label');
            textEntry = document.getElementById('text_entry');
            statusOutput = document.getElementById('status_output');
            micBtn = document.getElementById('mic_btn');

            // Setup button listener (only the mic now)
            micBtn.addEventListener('click', startSpeechRecognition);
            
            // Setup modal close button
            document.getElementById('modal_close_btn').addEventListener('click', () => {
                document.getElementById('error_modal').style.display = 'none';
            });
            
            logStatus("App initialized. Use the mic button to speak and start conversion.");
        });

        // --- Logging & Modal ---
        function logStatus(message) {
            console.log(message); // Also log to F12 console
            const timestamp = new Date().toLocaleTimeString([], { hour: '2-digit', minute: '2-digit', second: '2-digit', hour12: true }).toUpperCase();
            const logEntry = document.createElement('div');
            logEntry.innerHTML = `[${timestamp}] ${message}`;
            statusOutput.prepend(logEntry); // Add new log to the top
            while (statusOutput.children.length > 20) {
                statusOutput.removeChild(statusOutput.lastChild);
            }
        }

        function showModal(title, message) {
            document.getElementById('modal_title').textContent = title;
            document.getElementById('modal_message').textContent = message;
            document.getElementById('error_modal').style.display = 'flex';
        }
        
        // --- NEW: Speech Recognition Logic ---
        function startSpeechRecognition() {
            // Check for browser support
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!SpeechRecognition) {
                showModal("Browser Not Supported", "Your browser does not support the Web Speech API. Please try Chrome or Firefox.");
                return;
            }
            
            const recognition = new SpeechRecognition();
            recognition.lang = 'en-US'; // Use English
            recognition.interimResults = false; // We only want the final result
            recognition.maxAlternatives = 1;
            
            recognition.onstart = () => {
                logStatus("Listening...");
                micBtn.classList.add('listening', 'bg-red-600');
                micBtn.disabled = true;
                // Clear any previous text immediately
                textEntry.value = ""; 
            };
            
            recognition.onresult = (event) => {
                const speechResult = event.results[0][0].transcript;
                textEntry.value = speechResult; // Put the text in the box
                logStatus(`Speech recognized: "${speechResult}"`);
                
                // *** IMMEDIATE PROCESSING TRIGGERED HERE ***
                if (speechResult.trim() !== "") {
                    startSignAnimation(speechResult);
                }
            };
            
            recognition.onspeechend = () => {
                recognition.stop();
            };
            
            recognition.onerror = (event) => {
                logStatus(`Speech error: ${event.error}`);
                if (event.error === 'no-speech' || event.error === 'network') {
                    logStatus("No speech was detected. Please try again.");
                } else if (event.error === 'not-allowed') {
                    showModal("Permission Denied", "Microphone permission was denied. Please grant permission in your browser settings.");
                }
            };
            
            recognition.onend = () => {
                micBtn.classList.remove('listening', 'bg-red-600');
                micBtn.disabled = false;
            };
            
            try {
                recognition.start();
            } catch (e) {
                logStatus("Error starting recognition: " + e.message);
                showModal("Error", "Could not start speech recognition. It might already be running.");
            }
        }

        // --- Text -> Sign Logic (Modified to accept text directly) ---
        function startSignAnimation(text) {
            if (!text) return;
            
            logStatus(`Text→Sign: Starting conversion for "${text}"...`);
            
            // Stop any previous animations
            playingAnimation = false;
            
            // Build the frame sequence
            playFrames = [];
            // Use the text directly, then split into tokens
            let tokens = text.toLowerCase().split(/[\s,.\-!?;]+/); 
            
            tokens.forEach(token => {
                if (!token) return;
                
                // Find matching word
                if (WORDS_MAP[token]) {
                    playFrames.push({ type: "WORD", name: token, path: WORDS_MAP[token] });
                } else {
                    // Spell it out (letters/numbers)
                    for (const char of token) {
                        if (LETTERS_MAP[char]) {
                            playFrames.push({ type: "LETTER/NUM", name: char, path: LETTERS_MAP[char] });
                        } else {
                            playFrames.push({ type: "PAUSE", name: '...', path: null });
                        }
                    }
                }
                // Add a pause between each token
                playFrames.push({ type: "PAUSE", name: '...', path: null });
            });

            if (playFrames.length === 0) {
                logStatus("Text→Sign: No signable characters found.");
                return;
            }

            // Start playback
            playingAnimation = true;
            playIndex = 0;
            animationOverlay.style.display = 'flex'; // Show the animation player
            placeholder.style.display = 'none';
            ctx.clearRect(0, 0, canvas.width, canvas.height); // Clear canvas
            
            playNextFrame();
        }

        function playNextFrame() {
            if (!playingAnimation || playIndex >= playFrames.length) {
                // Animation finished
                playingAnimation = false;
                animationOverlay.style.display = 'none';
                placeholder.style.display = 'flex'; // Show placeholder
                logStatus("Text→Sign: Playback finished.");
                return; // Stop the loop
            }

            const frame = playFrames[playIndex];
            
            if (frame.type === "PAUSE") {
                // Show a blank screen for pauses
                animationImg.style.display = 'none';
                animationLabel.textContent = "...";
                logStatus("Text→Sign: Pausing...");
            } else {
                // Show the sign image
                animationImg.style.display = 'block';
                animationImg.src = frame.path;
                animationLabel.textContent = `SIGN: ${frame.name.toUpperCase()}`;
                logStatus(`Text→Sign: Showing sign '${frame.name}'`);
            }
            
            playIndex++; // Move to next frame
            // Wait and then call the next frame
            setTimeout(playNextFrame, FRAME_DURATION_MS);
        }

    </script>
</body>
</html>

